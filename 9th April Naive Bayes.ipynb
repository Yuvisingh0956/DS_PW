{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem is a mathematical formula that describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is named after Reverend Thomas Bayes and is fundamental in probability theory and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "The formula is: P(A|B) = (P(B|A) * P(A))/P(B), where P(A|B) is the probability of event A given that event B has occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is used in various fields, including:\n",
    "\n",
    "1. **Statistics and Probability:** It forms the basis for Bayesian statistics, helping update probabilities as new evidence emerges.\n",
    "\n",
    "2. **Machine Learning:** In applications like spam filtering, fraud detection, and medical diagnosis, Bayes' theorem is used for probabilistic reasoning and updating predictions with new data.\n",
    "\n",
    "3. **Finance:** It's employed in risk assessment, portfolio management, and pricing of financial instruments.\n",
    "\n",
    "4. **Medical Diagnosis:** Bayes' theorem is used to update the probability of a disease based on new diagnostic information.\n",
    "\n",
    "5. **Natural Language Processing:** In language models and text analysis, it helps in context-aware predictions.\n",
    "\n",
    "Overall, Bayes' theorem is a powerful tool for updating beliefs or predictions as new information becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related. Bayes' theorem is a way to express conditional probability in terms of prior probabilities. The relationship can be understood through the formula:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A))/P(B)\n",
    "\n",
    "Here:\n",
    "- P(A|B) is the conditional probability of event A given that event B has occurred.\n",
    "- P(B|A) is the conditional probability of event B given that event A has occurred.\n",
    "- P(A) and P(B) are the probabilities of events A and B, respectively.\n",
    "\n",
    "In essence, Bayes' theorem allows us to update our belief in the probability of event A given new evidence (event B). It relates the probability of A given B to the probability of B given A and the prior probability of A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "The choice of a specific Naive Bayes classifier (e.g., Gaussian Naive Bayes, Multinomial Naive Bayes, or Bernoulli Naive Bayes) depends on the nature of the data and the assumptions that can be made about the features. Here's a general guide:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   - **Data Type:** Suitable for continuous data that follows a normal distribution.\n",
    "   - **Example Use Cases:** Natural language processing tasks with continuous features, such as text classification.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - **Data Type:** Typically used for discrete data, like word counts in text classification problems.\n",
    "   - **Example Use Cases:** Text classification, spam detection, sentiment analysis.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   - **Data Type:** Appropriate for binary data (0s and 1s), often used in text classification problems.\n",
    "   - **Example Use Cases:** Document classification where features represent the presence or absence of certain words.\n",
    "\n",
    "In summary, consider the distribution of your data and the nature of your features when choosing a Naive Bayes classifier. Gaussian is suitable for continuous data, Multinomial for discrete data, and Bernoulli for binary data. It's also advisable to experiment with different models to see which one performs best for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Assignment: You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "## Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "## A 3 3 4 4 3 3 3\n",
    "## B 2 2 1 2 2 2 3\n",
    "## Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n",
    "\n",
    "To classify the new instance with features \\(X1 = 3\\) and \\(X2 = 4\\) using Naive Bayes, we can calculate the likelihood and then use Bayes' theorem to find the posterior probability for each class. Since the prior probabilities for classes A and B are assumed to be equal, they won't affect the comparison.\n",
    "\n",
    "Let's denote the classes as \\(C_A\\) and \\(C_B\\), and the features as \\(X1\\) and \\(X2\\). We need to calculate:\n",
    "\n",
    "1. \\(P(C_A | X1 = 3, X2 = 4)\\)\n",
    "2. \\(P(C_B | X1 = 3, X2 = 4)\\)\n",
    "\n",
    "Using Naive Bayes assumptions (independence of features given the class), we can calculate the likelihood as the product of the individual probabilities:\n",
    "\n",
    "\\[ P(C_i | X1 = 3, X2 = 4) \\propto P(X1 = 3 | C_i) \\times P(X2 = 4 | C_i) \\]\n",
    "\n",
    "For Class A:\n",
    "\\[ P(X1 = 3 | A) = 4/10 \\]\n",
    "\\[ P(X2 = 4 | A) = 3/10 \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ P(X1 = 3 | B) = 1/5 \\]\n",
    "\\[ P(X2 = 4 | B) = 3/5 \\]\n",
    "\n",
    "Now, we multiply these probabilities:\n",
    "\n",
    "\\[ P(C_A | X1 = 3, X2 = 4) = 4/10 * 3/10 \\]\n",
    "\\[ P(C_B | X1 = 3, X2 = 4) = 1/5 * 3/5 \\]\n",
    "\n",
    "Normalize these probabilities:\n",
    "\n",
    "\\[ P(C_A | X1 = 3, X2 = 4) = 12/100 \\]\n",
    "\\[ P(C_B | X1 = 3, X2 = 4) = 3/25 \\]\n",
    "\n",
    "Now, compare these probabilities. The class with the higher probability is the predicted class. In this case, \\(P(C_A | X1 = 3, X2 = 4)\\) is higher, so Naive Bayes would predict the new instance to belong to Class A."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
